{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, DistributedSampler\n",
    "import pytorch_lightning as pl\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "N_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Давайте загрузм данные и передадим в dataset пайплайн предобработки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "dataset1 = datasets.FashionMNIST(os.getcwd(), train=True, download=False,\n",
    "                   transform=transform)\n",
    "train_loader = DataLoader(dataset1, batch_size=BATCH_SIZE, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Создадим модель при помощи pytorch-lightening. У него много возможностей, в том числе легкое логирование всего в tensorboard, уже готовый конструктор для обучения моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(true, pred):\n",
    "    return sum(pred == true) / len(pred)\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size(0), -1)\n",
    "\n",
    "class LightModel(pl.LightningModule):\n",
    "    def __init__(self, learning_rate):\n",
    "        super(LightModel, self).__init__()\n",
    "        self.sequential_module = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            nn.Linear(1152, 64),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential_module(x)\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        pred = torch.squeeze(pred)\n",
    "        return {'loss': loss, 'accuracy': accuracy(pred, y)}\n",
    "    \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['accuracy'] for x in outputs]).mean()\n",
    "        print(f'Train loss = {avg_loss:.4f}, train accuracy = {avg_acc:.4f}')\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer чем-то похож на обучение моделей в keras. gpus=None говорит о том, что обучать мы будем все на CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_cpu = pl.Trainer(gpus=None, max_epochs=N_EPOCHS, progress_bar_refresh_rate=0)\n",
    "nn_model = LightModel(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time trainer_cpu.fit(nn_model, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_cpu.model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предыдущий вариант был долгим...Давайте возьмем гпу с индексом 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_gpu = pl.Trainer(gpus=[0], max_epochs=N_EPOCHS, progress_bar_refresh_rate=0)\n",
    "nn_model = LightModel(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time trainer_gpu.fit(nn_model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Намного лучше. А что если взять 2 гпу? Для этого нужно немного переписать код, так как мы будем использовать стратегию dp - батч делится на равные части между всеми задействованными gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightModel(pl.LightningModule):\n",
    "    def __init__(self, learning_rate):\n",
    "        super(LightModel, self).__init__()\n",
    "        self.sequential_module = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(16),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "\n",
    "            Flatten(),\n",
    "\n",
    "            nn.Linear(1152, 64),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(inplace=False),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(32, 10)\n",
    "        )\n",
    "        self.criterion = nn.NLLLoss()\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.sequential_module(x)\n",
    "        x = F.log_softmax(x, dim=-1)\n",
    "        return x\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = self.criterion(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1, keepdim=True)\n",
    "        pred = torch.squeeze(pred)\n",
    "        return {'loss': loss, 'accuracy' : accuracy(pred, y)}\n",
    "        \n",
    "    def training_step_end(self, outputs):\n",
    "        # only use when  on dp\n",
    "        avg_loss = outputs['loss'].mean()\n",
    "        avg_accuracy = outputs['accuracy'].mean()\n",
    "        return {'loss': avg_loss, 'accuracy' : avg_accuracy}\n",
    "        print(f'Train loss = {avg_loss:.4f}, accuracy = {avg_accuracy:.4f}')\n",
    "        \n",
    "    def training_epoch_end(self, outputs):\n",
    "        avg_loss = torch.stack([x['loss'] for x in outputs]).mean()\n",
    "        avg_acc = torch.stack([x['accuracy'] for x in outputs]).mean()\n",
    "        print(f'Train loss = {avg_loss:.4f}, train accuracy = {avg_acc:.4f}')\n",
    "        \n",
    "    def configure_optimizers(self):\n",
    "        optimizer = torch.optim.Adam(self.parameters(), lr=self.learning_rate)\n",
    "        return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPU можно выбирать, либо сказать сколько хотим взять и будут выбраны наименее загруженные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer_gpu = pl.Trainer(gpus=2, max_epochs=N_EPOCHS, progress_bar_refresh_rate=0, accelerator='dp', auto_select_gpus=True) #gpus=[0, 1]\n",
    "nn_model = LightModel(LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset1, batch_size=2*BATCH_SIZE, shuffle=False, num_workers=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time trainer_gpu.fit(nn_model, train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 512\n",
    "N_EPOCHS = 5\n",
    "LEARNING_RATE = 1e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим также данные fashion_mnist в tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = os.path.join(os.getcwd(), 'FashionMNIST/processed/training.pt')\n",
    "path_test = os.path.join(os.getcwd(), 'FashionMNIST/processed/test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "input_shape = (28, 28, 1)\n",
    "\n",
    "# the data, split between train and test sets\n",
    "#(x_train, y_train), (x_test, y_test) = keras.datasets.fashion_mnist.load_data()\n",
    "x_train, y_train = torch.load(path_train)\n",
    "x_train, y_train = x_train.numpy(), y_train.numpy()\n",
    "x_test, y_test = torch.load(path_test)\n",
    "x_test, y_test = x_test.numpy(), y_test.numpy()\n",
    "\n",
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "# Make sure images have shape (28, 28, 1)\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Модель возьмем такую же, попроуем воспроизвести)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        keras.Input(shape=input_shape),\n",
    "        layers.Conv2D(16, kernel_size=(3, 3), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.Conv2D(32, kernel_size=(3, 3), padding=\"same\"),\n",
    "        layers.ReLU(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        \n",
    "        layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\"),\n",
    "        layers.ReLU(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        \n",
    "        layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\"),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.ReLU(),\n",
    "        layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\"),\n",
    "        layers.ReLU(),\n",
    "        layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "        \n",
    "        layers.Flatten(),\n",
    "        layers.Dense(64),\n",
    "        layers.ReLU(),\n",
    "        layers.Dense(32),\n",
    "        layers.ReLU(),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Параметров вроде столько же, все похоже. Для начала обучим на CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/CPU:0'):\n",
    "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "На GPU первый запуск очень долгий. Во время него идет процесс резрвирования памяти на gpu, перенос данных и весов + как мы уже знаем, первый запуск чего-либо на GPU часто медленный"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.device('/GPU:0'):\n",
    "    model.fit(x_train, y_train, batch_size=BATCH_SIZE, epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучать на нескольких GPU в рамках однйо машины также просто, нужно создать стратегию и внутри нее определить модель. Также можно выбирать колчество GPU и индексы. Используйте столько, сколько нужно, не жадничайте)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:1\", \"/gpu:2\"])\n",
    "print('Number of devices: {}'.format(strategy.num_replicas_in_sync))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=LEARNING_RATE)\n",
    "with strategy.scope():\n",
    "  # Everything that creates variables should be under the strategy scope.\n",
    "  # In general this is only model construction & `compile()`.\n",
    "    model = keras.Sequential(\n",
    "        [\n",
    "            keras.Input(shape=input_shape),\n",
    "            layers.Conv2D(16, kernel_size=(3, 3), padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(32, kernel_size=(3, 3), padding=\"same\"),\n",
    "            layers.ReLU(),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(64, kernel_size=(3, 3), padding=\"same\"),\n",
    "            layers.ReLU(),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "            layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\"),\n",
    "            layers.BatchNormalization(),\n",
    "            layers.ReLU(),\n",
    "            layers.Conv2D(128, kernel_size=(3, 3), padding=\"same\"),\n",
    "            layers.ReLU(),\n",
    "            layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)),\n",
    "\n",
    "            layers.Flatten(),\n",
    "            layers.Dense(64),\n",
    "            layers.ReLU(),\n",
    "            layers.Dense(32),\n",
    "            layers.ReLU(),\n",
    "            layers.Dropout(0.5),\n",
    "            layers.Dense(num_classes, activation=\"softmax\"),\n",
    "        ]\n",
    "    )\n",
    "    model.compile(loss=\"categorical_crossentropy\", optimizer=optimizer, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очень долгий первый запуск. Ну логично, создаются полные копии сетки на 2х GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, batch_size=2*BATCH_SIZE, epochs=N_EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Домашнее задание \\ проект"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В данном проекте вам нужно будет провести стандартную работу - загрузить данные, поисследовать их, сделать модельку. Сразу оговорюсь, что подбор параметров, интересные архитектуры...на это я внимания обращать не буду, у нас курс не про ML. Главное - это использования GPU. Что нужно?\n",
    "\n",
    "    1) Загрузить данны при помощи cudf\\dask-cudf\n",
    "    2) Произвести базовый анализ данных (распределение классов, средние значения фичей по классам и вот это вот все). Любые преобразования данных на ваше усмотрение (только комментируйте=) )\n",
    "    3) Попробуйте в ходе анализа \\ обработки найти применение cuda.jit и cupy (достаточно по 1 примеру, даже искуственному)\n",
    "    4) Взять два метода снижения размерности из cuml (на лекции был UMAP, еще есть tSNE, tSVD, PCA...), обучить их и визуализировать наши классы в пространстве размерности 2 (раскрасить классы будет хорошей идеей)\n",
    "    5) Обучите нейронку на GPU\\Multi-GPU, а также какую-нибудь еще модельку на GPU\\Multi-GPU.\n",
    "\n",
    "Если в пункте 5 будет Multi-GPU - это дополнительные баллы, а также если еще добавите, например, метод кластеризации просто для сравнения =)\n",
    "\n",
    "P.S. прошу в коде давать комментарии того, что делаете. Пункты 4 и 5 также зачту за домашку 3 занятия.\n",
    "\n",
    "Данные находятся в файле Train_Set_90621.csv\n",
    "Amount Defaulted - эту переменную нужно удалить=)\n",
    "\n",
    "И все на GPU, никаких любимых pandas, numpy и прочего)) Думаю, из описания понятно, как я буду оценивать работу)\n",
    "\n",
    "Цель всего этого - чтобы вы побольше потыкали GPU"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
