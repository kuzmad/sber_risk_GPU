{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_classification\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from cuml.ensemble import RandomForestClassifier as cuRFC\n",
    "from cuml.datasets.classification import make_classification as make_classification_cu\n",
    "from cuml.preprocessing.model_selection import train_test_split as train_test_split_cu\n",
    "import cudf\n",
    "from cuml.metrics import accuracy_score as accuracy_score_cu\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Есть в последних версиях\n",
    "from cuml.experimental.explainer import KernelExplainer as cuKE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cuML - это по сути sklearn, но только на GPU, хотя и не все алгоритмы в нем реализованы, как и в остальных библиотеках экосистемы rapids.\n",
    "\n",
    "Простой пример: сгенерируем датасет для бинарной классификации, разделим стандартно на обучающее и тестовое множесто, обучим RandomForest. \n",
    "\n",
    "P.S. тут не про подбор параметров и наилучший способ обучения моделей =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# параметры \n",
    "n_samples = 10000000\n",
    "n_features = 20\n",
    "n_classes = 2\n",
    "\n",
    "# random forest depth and size\n",
    "n_estimators = 30\n",
    "max_depth = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "X, y = make_classification(n_classes=n_classes, n_features=n_features, n_samples=n_samples, random_state=0, class_sep=0.7)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "X_cu, y_cu = make_classification_cu(n_classes=n_classes, n_features=n_features, n_samples=n_samples, random_state=0, class_sep=0.7)\n",
    "X_train_cu, X_test_cu, y_train_cu, y_test_cu = train_test_split_cu(X_cu, y_cu, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cu.device"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Прирост есть, да и данные сразу на GPU.\n",
    "\n",
    "А что с обучением моделей? (даже при первом запуске все хорошо, но при повтороном еще лучше, надо \"прогревать\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "print(f'Количество ядер CPU: {os.cpu_count()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "mem_bytes = os.sysconf('SC_PAGE_SIZE') * os.sysconf('SC_PHYS_PAGES')  # e.g. 4015976448\n",
    "mem_gib = mem_bytes/(1024.**3)\n",
    "print(mem_gib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=0).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, random_state=0, n_jobs=-1).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time print(f'Train: {accuracy_score(y_train, clf.predict(X_train)):.2f}, Test: {accuracy_score(y_test, clf.predict(X_test)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time clf_cu = cuRFC(n_estimators=n_estimators, max_depth=max_depth, random_state=0).fit(X_train_cu, y_train_cu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time print(f'''Train: {accuracy_score_cu(y_train_cu, clf_cu.predict(X_train_cu)):.2f},\\\n",
    "                Test: {accuracy_score_cu(y_test_cu, clf_cu.predict(X_test_cu)):.2f}''')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, обучение проходит хорошо и довольно быстро, намного быстрее, чем на CPU, даже при большом количестве ядер (не говоря уже об одном)\n",
    "\n",
    "Давайте еще посмотрим, что были у нас за данные=)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.manifold.umap import UMAP as cuUMAP\n",
    "import umap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "umap_cpu = umap.UMAP(n_neighbors=30, n_components=2).fit(X)\n",
    "umap_cpu_embeddings = umap_cpu.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = zip(*umap_cpu_embeddings.tolist())\n",
    "plt.scatter(a, b, c=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "umap_gpu = cuUMAP(n_neighbors=30, n_components=2).fit(X)\n",
    "umap_gpu_embeddings = umap_gpu.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b = zip(*umap_gpu_embeddings.tolist())\n",
    "plt.scatter(a, b, c=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сохранение и загурзка объектов (обучение на одном GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from joblib import dump, load\n",
    "\n",
    "dump(clf_cu, 'RF.model')\n",
    "model = load('RF.model')\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тажкже можно через pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "pickle.dump(clf_cu, open(\"RF.pkl\", \"wb\"))\n",
    "model = pickle.load(open(\"RF.pkl\", \"rb\"))\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Если модель обучалась на нескольких GPU, то придется сделать одно действие:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_gpu_model = model.get_combined_model()\n",
    "pickle.dump(single_gpu_model, open(\"single_gpu_model.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Так, как сохранять модель, обученную на нескольких GPU показали, а обучать то как?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cuml.dask.ensemble import RandomForestClassifier as daskRFC\n",
    "from dask_cuda import LocalCUDACluster\n",
    "from dask.distributed import Client\n",
    "from cuml.dask.common import utils as dask_utils\n",
    "import dask_cudf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "cmd = \"hostname --all-ip-addresses\"\n",
    "process = subprocess.Popen(cmd.split(), stdout=subprocess.PIPE)\n",
    "output, error = process.communicate()\n",
    "IPADDR = str(output.decode()).split()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster = LocalCUDACluster(ip=IPADDR, local_directory='/data/kuznetsov2-md/TEMP/', CUDA_VISIBLE_DEVICES='0,1')\n",
    "client = Client(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers = client.has_what().keys()\n",
    "n_workers = len(workers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cu, y_cu = make_classification_cu(n_classes=n_classes, n_features=n_features, n_samples=n_samples, random_state=0, class_sep=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Сначала нужно конвертировать данные в cudf, типы float32 и int32, на 64 будет ругаться=)\n",
    "X_train_cudf = cudf.DataFrame(X_cu)\n",
    "y_train_cu = y_cu.astype('int32')\n",
    "y_train_cudf = cudf.Series(y_train_cu)\n",
    "\n",
    "# Разбиваем данные на партиции (обычно сколько гпу, столькои  партиций)\n",
    "X_train_dask = dask_cudf.from_cudf(X_train_cudf, npartitions=n_workers).persist()\n",
    "y_train_dask = dask_cudf.from_cudf(y_train_cudf, npartitions=n_workers).persist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time \n",
    "rf = daskRFC(n_estimators=n_estimators, max_depth=max_depth, random_state=0,\n",
    "                   ignore_empty_partitions=True, client=client).fit(X_train_dask, y_train_dask)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу после обучения распределенной модели может не получится ее сохранить, метод get_combined_model вернет путой объект. Если так происходит, то можно 1 раз вызвать метод predict, тогда модель уже будет сериализованным объектом и нормально сохранится"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.predict(X_train_dask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_gpu_model = rf.get_combined_model()\n",
    "pickle.dump(single_gpu_model, open(\"single_gpu_model.pkl\", \"wb\"))\n",
    "model = pickle.load(open(\"single_gpu_model.pkl\", \"rb\"))\n",
    "model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
